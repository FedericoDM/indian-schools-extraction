{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Data from Schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Packages\n",
    "import time\n",
    "import requests\n",
    "import certifi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://www.redacademica.edu.co/colegios?name=&field_localidad_target_id=All&page=0\"\n",
    "HEADERS = { \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36\",\n",
    "           \"Host\": \"www.redacademica.edu.co\" }\n",
    "LAST_PAGE = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all a's with href\n",
    "def get_urls_dict(soup):\n",
    "    \"\"\"\n",
    "    Getting school URLS from the given soup object\n",
    "    \"\"\"\n",
    "    urls_dict = {}\n",
    "    a_objects = soup.find_all(\"a\", href=True)\n",
    "    for a_object in a_objects:\n",
    "        if \"colegios/\" in str.lower(a_object[\"href\"]):\n",
    "            new_url = \"https://www.redacademica.edu.co\" + a_object[\"href\"]\n",
    "            urls_dict[a_object.text] = new_url\n",
    "\n",
    "    if \"\\n\\n\\n\\n\" in urls_dict:\n",
    "        del urls_dict[\"\\n\\n\\n\\n\"]\n",
    "\n",
    "    return urls_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_schools_df(urls_dict):\n",
    "    \"\"\"\n",
    "    Takes a dictionary of school names and urls and returns a dataframe with all the info\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    urls_dict : dict\n",
    "        Dictionary of school names and urls\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    schools_df : pd.DataFrame\n",
    "        Dataframe with all the info\n",
    "    \"\"\"\n",
    "    # Getting info from all schools\n",
    "    school_dicts = []\n",
    "\n",
    "    for school_name, school_url in urls_dict.items():\n",
    "        print(f\"Getting info from {school_name}...\")\n",
    "        # Create school dict\n",
    "        school_dict = {}\n",
    "        school_dict[\"school_name\"] = school_name\n",
    "        school_dict[\"school_url\"] = school_url\n",
    "        # Get school info\n",
    "        school_r = requests.get(school_url, headers=HEADERS)\n",
    "        school_soup = BeautifulSoup(school_r.content, \"html.parser\")\n",
    "        info_container = school_soup.find(\"ul\", {\"class\": \"school-info__list\"})\n",
    "        if not info_container:\n",
    "            print(f\"Skipping {school_name}...\")     \n",
    "            continue\n",
    "        else:\n",
    "            column_names = info_container.find_all(\"h4\")\n",
    "            list_elements = info_container.find_all(\"li\")\n",
    "            for column_name, list_element in zip(column_names, list_elements):\n",
    "                # Remove column name from raw text\n",
    "                clean_col_name = column_name.text\n",
    "                raw_text = list_element.text.replace(clean_col_name, \"\")\n",
    "                # Remove new lines and strip\n",
    "                raw_text = raw_text.replace(\"\\n\", \" \").strip()\n",
    "                # Add to school dict\n",
    "                school_dict[clean_col_name] = raw_text\n",
    "\n",
    "        school_dicts.append(school_dict)\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    # Create schools df\n",
    "    schools_df = pd.DataFrame.from_dict(school_dicts)\n",
    "\n",
    "    return schools_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ================ Getting page 0... ==================\n",
      "Found 20 schools in page 0...\n",
      "Getting info from Colegio Aquileo Parra...\n",
      "Getting info from IED Colegio El Verjon...\n",
      "Getting info from Colegio Altamira Sur Oriental (IED)...\n",
      "Getting info from Colegio Montebello (IED)...\n",
      "Getting info from Colegio Atenas (IED)...\n",
      "Getting info from Colegio Jose Joaquin Castro Martinez (IED)...\n",
      "Getting info from Colegio Entre Nubes Sur Oriental (IED)...\n",
      "Getting info from Colegio Diego Montaña Cuellar (IED)...\n",
      "Getting info from Colegio Gran Yomasa I. E. D....\n",
      "Getting info from Colegio Marco Fidel Suárez (IED)...\n",
      "Getting info from Colegio Motorista (CED)...\n"
     ]
    }
   ],
   "source": [
    "all_schools_df = pd.DataFrame()\n",
    "pages = [num for num in range(0, LAST_PAGE)]\n",
    "\n",
    "for page in pages:\n",
    "    print(f\" ================ Getting page {page}... ==================\")\n",
    "    page_url = BASE_URL.replace(\"page=0\", f\"page={page}\")\n",
    "    r = requests.get(BASE_URL, headers=HEADERS)\n",
    "    soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "    urls_dict = get_urls_dict(soup)\n",
    "    print(f\"Found {len(urls_dict)} schools in page {page}...\")\n",
    "    schools_df = get_schools_df(urls_dict)\n",
    "    schools_df.to_csv(f\"schools_{page}.csv\", index=False)\n",
    "    all_schools_df = pd.concat([all_schools_df, schools_df], ignore_index=True)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_df.to_csv(\"schools.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb56503e6c8360dc89efe5118cedf5301d846b45ea25a73e798949856c7eed07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
